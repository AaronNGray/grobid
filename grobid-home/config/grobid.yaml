# this is the configuration file for the GROBID instance

grobid:
  # where all the Grobid resources are stored (models, lexicon, native libraries, etc.), normally no need to change
  grobidHome: "grobid-home"

  # path relative to the grobid-home path (e.g. grobid-home/tmp)
  temp: "tmp"
  
  # normally nothing to change here, path relative to the grobid-home path (e.g. grobid-home/lib)
  nativelibrary: "lib"

  pdf:
    pdfalto:
      # path relative to the grobid-home path (e.g. grobid-home/pdf2xml), you don't want to change this normally
      path: "pdf2xml"
      # security for PDF parsing
      memory_limit_mb: 6096
      timeout_sec: 60

    # security relative to the PDF parsing result
    blocks_max: 100000
    tokens_max: 1000000

  consolidation:
    # define the bibliographical data consolidation service to be used, either "crossref" for CrossRef REST API or 
    # "glutton" for https://github.com/kermitt2/biblio-glutton
    service: "crossref"
    #service: "glutton"
    glutton:
      host: "cloud.science-miner.com/glutton"
      port: 
      #host: "localhost"
      #port: 8080
    crossref:
      mailto: 
      # to use crossref web API, you need normally to use it politely and to indicate an email address here, e.g. 
      #mailto: "toto@titi.tutu"
      token:
      # to use Crossref metadata plus service (available by subscription)
      #token: "yourmysteriouscrossrefmetadataplusauthorizationtokentobeputhere"

  proxy:
    # proxy to be used when doing external call to the consolidation service
    host: 
    port: 

  # CORS configuration for the GROBID web API service
  corsAllowedOrigins: "*"
  corsAllowedMethods: "OPTIONS,GET,PUT,POST,DELETE,HEAD"
  corsAllowedHeaders: "X-Requested-With,Content-Type,Accept,Origin"

  # the actual implementation for language recognition to be used
  language_detector_factory: "org.grobid.core.lang.impl.CybozuLanguageDetectorFactory"

  # the actual implementation for optional sentence segmentation to be used (Pragmatic_Segmenter or OpenNLP)
  sentence_detector_factory: "org.grobid.core.lang.impl.PragmaticSentenceDetectorFactory"
  #sentence_detector_factory: "org.grobid.core.lang.impl.OpenNLPSentenceDetectorFactory"
  
  # parallel processing security - change with care according to your CPU/GPU capacities
  # maximum parallel connections allowed
  max_connections: 10  
  # maximum time wait to get a connection when the pool is full (in seconds)
  pool_max_wait: 1

  # number of threads for training the wapiti models (0 to use all available processors)
  nb_threads: 0

  delft:
    # delft installation path if Deep Learning architectures are used to implement one of the sequence labeling model, 
    # embeddings are usually compiled as lmdb under delft/data (this paramter is ignored if only featured-engineered CRF are used)
    install: "../delft"
    python_virtualEnv:

  models:
    # we configure here how each sequence labeling model should be implemented
    # for feature-engineered CRF, use "wapiti" and possible training parameters are window, epsilon and max_epoch
    # for Deep Learning, use "delft" and select the target DL architecture (see DeLFT library), the training 
    # parameters then depends on this selected DL architecture 

    - name: "segmentation"
      # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.0000001
      window: 50
      nbMaxIterations: 2000

    - name: "fulltext"
      # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.0001
      window: 20
      nbMaxIterations: 1500

    - name: "header"
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 30
      nbMaxIterations: 1500
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "reference-segmenter"
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.00001
      window: 20
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "name-header"
      engine: "wapiti"
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "name-citation"
      engine: "wapiti"
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "date"
      engine: "wapiti"
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "figure"
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.00001
      window: 20
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "table"
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.00001
      window: 20
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "affiliation-address"
      engine: "wapiti"
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"

    - name: "citation"
      engine: "wapiti"
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.00001
      window: 50
      nbMaxIterations: 3000
      #engine: "delft"
      #architecture: "BidLSTM_CRF_FEATURES"
      #architecture: "scibert"
      #useELMo: false

  # for **service only**: how to load the models, 
  # false -> models are loaded when needed (default), avoiding putting in memory useless models but slow down significantly
  #          the service at first call
  # true -> all the models are loaded into memory at the server startup, slow the start of the services and models not
  #         used will take some memory, but server is immediatly warm and ready
  modelPreload: false

server:
    type: custom
    applicationConnectors:
    - type: http
      port: 8070
    adminConnectors:
    - type: http
      port: 8071
    registerDefaultExceptionMappers: false

logging:
  level: INFO
  loggers:
    org.apache.pdfbox.pdmodel.font.PDSimpleFont: "OFF"
  appenders:
    - type: console
      threshold: ALL
      timeZone: UTC
    - type: file
      currentLogFilename: logs/grobid-service.log
      threshold: ALL
      archive: true
      archivedLogFilenamePattern: logs/grobid-service-%d.log
      archivedFileCount: 5
      timeZone: UTC
