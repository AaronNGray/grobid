Recap results for each fold:


====================== Fold 0 ======================
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_0.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment3228984326275118652.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment1813409383143806474.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        98.32        64.66        49.71        56.21        173
<educationalInstitution> 99.02        12.5         10.42        11.36        48
<fundingAgency>      92.39        60.41        58.5         59.44        759
<grantName>          99.21        36.84        12.07        18.18        58
<grantNumber>        97.65        81.21        78.99        80.09        476
<individual>         97.08        88.95        92.38        90.63        1220
<otherInstitution>   97.36        21.74        12.66        16           158
<projectName>        98.96        18.75        9.52         12.63        63
<researchInstitution> 98.78        24           16.9         19.83        71

all (micro avg.)     97.64        73.58        68.84        71.13        3026
all (macro avg.)     97.64        45.45        37.91        40.49        3026

===== Instance-level results =====

Total expected instances:   590
Correct instances:          215
Instance-level recall:      36.44



====================== Fold 1 ======================
Saving model in /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment_nfold_1.wapiti
Training input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment142904288407148388.train
Evaluation input data: /Users/tkristan/Desktop/Tanti/grobid/grobid-home/tmp/acknowledgment3655301334481644753.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        98.3         58.86        60.39        59.62        154
<educationalInstitution> 99.06        23.68        18           20.45        50
<fundingAgency>      93.36        65.17        63.96        64.56        702
<grantName>          99.37        15           9.09         11.32        33
<grantNumber>        98.15        81.72        82.37        82.04        380
<individual>         96.93        89.12        91.29        90.19        1148
<otherInstitution>   96.85        22.83        11.41        15.22        184
<projectName>        98.69        17.07        10           12.61        70
<researchInstitution> 99           36.11        20.31        26           64

all (micro avg.)     97.75        74.29        70.23        72.2         2785
all (macro avg.)     97.75        45.51        40.76        42.45        2785

===== Instance-level results =====

Total expected instances:   591
Correct instances:          238
Instance-level recall:      40.27



Summary results:
Worst fold

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        98.32        64.66        49.71        56.21        173
<educationalInstitution> 99.02        12.5         10.42        11.36        48
<fundingAgency>      92.39        60.41        58.5         59.44        759
<grantName>          99.21        36.84        12.07        18.18        58
<grantNumber>        97.65        81.21        78.99        80.09        476
<individual>         97.08        88.95        92.38        90.63        1220
<otherInstitution>   97.36        21.74        12.66        16           158
<projectName>        98.96        18.75        9.52         12.63        63
<researchInstitution> 98.78        24           16.9         19.83        71

all (micro avg.)     97.64        73.58        68.84        71.13        3026
all (macro avg.)     97.64        45.45        37.91        40.49        3026

===== Instance-level results =====

Total expected instances:   590
Correct instances:          215
Instance-level recall:      36.44

Best fold:

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<affiliation>        98.3         58.86        60.39        59.62        154
<educationalInstitution> 99.06        23.68        18           20.45        50
<fundingAgency>      93.36        65.17        63.96        64.56        702
<grantName>          99.37        15           9.09         11.32        33
<grantNumber>        98.15        81.72        82.37        82.04        380
<individual>         96.93        89.12        91.29        90.19        1148
<otherInstitution>   96.85        22.83        11.41        15.22        184
<projectName>        98.69        17.07        10           12.61        70
<researchInstitution> 99           36.11        20.31        26           64

all (micro avg.)     97.75        74.29        70.23        72.2         2785
all (macro avg.)     97.75        45.51        40.76        42.45        2785

===== Instance-level results =====

Total expected instances:   591
Correct instances:          238
Instance-level recall:      40.27


Average over 2 folds:

label                accuracy     precision    recall       f1           support

<affiliation>        98.31        61.76        55.05        57.91        327
<educationalInstitution> 99.04        18.09        14.21        15.91        98
<fundingAgency>      92.88        62.79        61.23        62           1461
<grantName>          99.29        25.92        10.58        14.75        91
<grantNumber>        97.9         81.47        80.68        81.06        856
<individual>         97           89.03        91.83        90.41        2368
<otherInstitution>   97.11        22.28        12.04        15.61        342
<projectName>        98.83        17.91        9.76         12.62        133
<researchInstitution> 98.89        30.06        18.61        22.92        135

all                  97.69        73.93        69.54        71.67

===== Instance-level results =====

Total expected instances:   590.5
Correct instances:          226.5
Instance-level recall:      38.36


N-Fold evaluation for acknowledgment model is realized in 3839064 ms