Recap results for each fold:


====================== Fold 0 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_0.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph7925806707426894433.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph6026019162135966779.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      95.24        0            0            0            2
<back>               93.65        0            0            0            3
<cover>              90.48        50           50           50           6
<dedication>         90.48        25           25           25           4
<glossary>           96.83        0            0            0            2
<preface>            85.71        0            0            0            5
<publisher>          96.83        0            0            0            1
<summary>            96.83        0            0            0            1
<title>              87.3         0            0            0            3
<toc>                95.24        50           33.33        40           3
<tof>                95.24        0            0            0            2
<unit>               85.71        0            0            0            5

all (micro avg.)     92.46        16.67        13.51        14.93        37
all (macro avg.)     92.46        10.42        9.03         9.58         37

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 1 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_1.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph9000601034433938800.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph4703089957364880616.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      96.12        33.33        33.33        33.33        3
<cover>              95.15        71.43        62.5         66.67        8
<dedication>         94.17        60           42.86        50           7
<glossary>           95.15        0            0            0            2
<preface>            86.41        0            0            0            7
<publisher>          89.32        0            0            0            7
<summary>            99.03        0            0            0            1
<title>              84.47        0            0            0            8
<toc>                93.2         0            0            0            4
<tof>                96.12        0            0            0            2
<unit>               82.52        0            0            0            7

all (micro avg.)     91.97        16.98        16.07        16.51        56
all (macro avg.)     91.97        14.98        12.61        13.64        56

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 2 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_2.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph6359270988873699235.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5835219887296458685.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      97.85        0            0            0            2
<cover>              94.62        66.67        57.14        61.54        7
<dedication>         94.62        0            0            0            3
<glossary>           91.4         0            0            0            1
<preface>            84.95        0            0            0            6
<publisher>          95.7         50           50           50           4
<summary>            98.92        0            0            0            1
<title>              92.47        50           28.57        36.36        7
<toc>                87.1         0            0            0            6
<tof>                97.85        0            0            0            1
<unit>               75.27        0            0            0            9

all (micro avg.)     91.89        15.38        17.02        16.16        47
all (macro avg.)     91.89        15.15        12.34        13.45        47

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 3 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_3.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph1107475989616162687.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5956771151161781803.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      95.88        0            0            0            3
<cover>              93.81        62.5         62.5         62.5         8
<dedication>         94.85        66.67        33.33        44.44        6
<glossary>           97.94        0            0            0            2
<preface>            85.57        0            0            0            9
<publisher>          95.88        60           60           60           5
<summary>            98.97        0            0            0            1
<title>              86.6         25           22.22        23.53        9
<toc>                91.75        0            0            0            4
<tof>                97.94        0            0            0            1
<unit>               82.47        11.11        10           10.53        10

all (micro avg.)     92.88        29.55        22.41        25.49        58
all (macro avg.)     92.88        20.48        17.1         18.27        58

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 4 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_4.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph783430068191397379.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph7971915468476325359.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      96.94        0            0            0            2
<cover>              95.92        75           75           75           8
<dedication>         93.88        0            0            0            3
<glossary>           95.92        0            0            0            3
<preface>            86.73        0            0            0            10
<publisher>          88.78        16.67        14.29        15.38        7
<reference>          98.98        0            0            0            1
<summary>            96.94        0            0            0            2
<title>              85.71        14.29        11.11        12.5         9
<toc>                91.84        0            0            0            4
<tof>                98.98        0            0            0            1
<unit>               82.65        9.09         12.5         10.53        8

all (micro avg.)     92.77        20           15.52        17.48        58
all (macro avg.)     92.77        9.59         9.41         9.45         58

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 5 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_5.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph1508990268032487273.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph7517041800878899443.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      93.67        0            0            0            2
<cover>              93.67        80           50           61.54        8
<dedication>         94.94        50           25           33.33        4
<glossary>           98.73        0            0            0            1
<preface>            87.34        0            0            0            7
<publisher>          88.61        20           16.67        18.18        6
<summary>            98.73        0            0            0            1
<title>              93.67        25           33.33        28.57        3
<toc>                86.08        0            0            0            6
<unit>               78.48        0            0            0            8

all (micro avg.)     91.39        19.44        15.22        17.07        46
all (macro avg.)     91.39        17.5         12.5         14.16        46

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 6 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_6.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5486835047880160593.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph4078429053459684357.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      96.7         0            0            0            1
<back>               97.8         0            0            0            1
<biography>          98.9         0            0            0            1
<cover>              90.11        42.86        37.5         40           8
<dedication>         90.11        0            0            0            6
<glossary>           97.8         0            0            0            1
<preface>            87.91        25           11.11        15.38        9
<publisher>          93.41        0            0            0            4
<summary>            96.7         50           33.33        40           3
<title>              86.81        25           10           14.29        10
<toc>                93.41        25           25           25           4
<unit>               86.81        25           25           25           8

all (micro avg.)     93.04        23.68        16.07        19.15        56
all (macro avg.)     93.04        16.07        11.83        13.31        56

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 7 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_7.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph1048441498482732555.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph9213734729973479386.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      94.44        25           25           25           4
<back>               97.22        0            0            0            0
<cover>              94.44        62.5         62.5         62.5         8
<dedication>         87.04        0            0            0            3
<glossary>           97.22        0            0            0            2
<preface>            84.26        8.33         14.29        10.53        7
<publisher>          89.81        0            0            0            7
<summary>            97.22        0            0            0            2
<title>              92.59        25           16.67        20           6
<toc>                91.67        14.29        25           18.18        4
<tof>                99.07        0            0            0            1
<unit>               83.33        0            0            0            7

all (micro avg.)     91.92        14.29        17.65        15.79        51
all (macro avg.)     91.92        12.28        13.04        12.38        51

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 8 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_8.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5551862371277756926.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5376101879778140535.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      97.53        50           50           50           2
<back>               97.53        0            0            0            1
<cover>              93.83        57.14        66.67        61.54        6
<dedication>         95.06        50           25           33.33        4
<glossary>           93.83        0            0            0            3
<preface>            88.89        0            0            0            7
<publisher>          97.53        75           75           75           4
<summary>            95.06        0            0            0            2
<title>              85.19        33.33        33.33        33.33        9
<toc>                90.12        20           20           20           5
<tof>                98.77        0            0            0            1
<unit>               95.06        71.43        71.43        71.43        7

all (micro avg.)     94.03        41.86        35.29        38.3         51
all (macro avg.)     94.03        29.74        28.45        28.72        51

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0



====================== Fold 9 ======================
Saving model in /data/workspace/tkristan/grobid/grobid-home/tmp/monograph_nfold_9.wapiti
Training input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph9014467963602957332.train
Evaluation input data: /data/workspace/tkristan/grobid/grobid-home/tmp/monograph5476969370533774183.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      93.68        0            0            0            4
<biography>          98.95        0            0            0            1
<cover>              97.89        87.5         87.5         87.5         8
<dedication>         93.68        0            0            0            4
<preface>            88.42        0            0            0            7
<publisher>          89.47        25           12.5         16.67        8
<summary>            98.95        0            0            0            1
<title>              80           0            0            0            12
<toc>                88.42        0            0            0            5
<tof>                98.95        0            0            0            1
<unit>               83.16        12.5         10           11.11        10

all (micro avg.)     91.96        21.95        14.75        17.65        61
all (macro avg.)     91.96        11.36        10           10.48        61

===== Instance-level results =====

Total expected instances:   9
Correct instances:          0
Instance-level recall:      0



Summary results:
Worst fold

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      95.24        0            0            0            2
<back>               93.65        0            0            0            3
<cover>              90.48        50           50           50           6
<dedication>         90.48        25           25           25           4
<glossary>           96.83        0            0            0            2
<preface>            85.71        0            0            0            5
<publisher>          96.83        0            0            0            1
<summary>            96.83        0            0            0            1
<title>              87.3         0            0            0            3
<toc>                95.24        50           33.33        40           3
<tof>                95.24        0            0            0            2
<unit>               85.71        0            0            0            5

all (micro avg.)     92.46        16.67        13.51        14.93        37
all (macro avg.)     92.46        10.42        9.03         9.58         37

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0

Best fold:

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<advertisement>      97.53        50           50           50           2
<back>               97.53        0            0            0            1
<cover>              93.83        57.14        66.67        61.54        6
<dedication>         95.06        50           25           33.33        4
<glossary>           93.83        0            0            0            3
<preface>            88.89        0            0            0            7
<publisher>          97.53        75           75           75           4
<summary>            95.06        0            0            0            2
<title>              85.19        33.33        33.33        33.33        9
<toc>                90.12        20           20           20           5
<tof>                98.77        0            0            0            1
<unit>               95.06        71.43        71.43        71.43        7

all (micro avg.)     94.03        41.86        35.29        38.3         51
all (macro avg.)     94.03        29.74        28.45        28.72        51

===== Instance-level results =====

Total expected instances:   8
Correct instances:          0
Instance-level recall:      0


Average over 10 folds:

label                accuracy     precision    recall       f1           support

<advertisement>      95.81        10.83        10.83        10.83        25
<back>               38.62        0            0            0            5
<biography>          19.78        0            0            0            2
<cover>              93.99        65.56        61.13        62.88        75
<dedication>         92.88        25.17        15.12        18.61        44
<glossary>           86.48        0            0            0            17
<preface>            86.62        3.33         2.54         2.59         74
<publisher>          92.53        24.67        22.85        23.52        53
<reference>          9.9          0            0            0            1
<summary>            97.74        5            3.33         4            15
<title>              87.48        19.76        15.52        16.86        76
<toc>                90.88        10.93        10.33        10.32        45
<tof>                78.29        0            0            0            10
<unit>               83.55        12.91        12.89        12.86        79

all                  92.43        21.98        18.35        19.85

===== Instance-level results =====

Total expected instances:   8.1
Correct instances:          0
Instance-level recall:      0


N-Fold evaluation for monograph model is realized in 23813740 ms